{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1zlDomIvfKF1ibDpYIjAPK-aY1BDJ1pQC",
      "authorship_tag": "ABX9TyNVeqnF6voiTVqDb9AdQ+lq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/addone/datascience-gt/blob/main/TM_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備\n",
        "\n",
        "文系分野の研究では、論文、書籍、新聞記事、Webページ、SNS、アンケートへの自由回答など、テキストデータを扱うことが一般的です。\n",
        "\n",
        "テキストマイニングは膨大な量の文章データに特化した分析手法で、キーワード検索だけでは見つけられないような、新たな知見やパターンを発見することができます。\n",
        "\n",
        "（参考：[テキストマイニングとは](https://gmo-research.ai/research-column/text-mining/)）\n",
        "\n",
        "テキストマイニングには**形態素の解析**が必要です。まずは形態素解析器[janome](https://janome.mocobeta.dev/ja/)をインストールします。\n",
        "\n",
        "形態素解析には**辞書**が必要であるが、janomeの場合は日本語解析エンジン[MeCab](http://taku910.github.io/mecab/)用辞書が内蔵されたため、単独インストール不要となります。\n",
        "\n",
        "（参考：[形態素解析とは](https://www.cogent.co.jp/blog/morphological-analysis-natural-language-processing/)）"
      ],
      "metadata": {
        "id": "eOhCMwO8Nz6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install janome"
      ],
      "metadata": {
        "id": "HB7obUHDQGM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "日本語文章を扱う場合、日本語フォントおよびグラフへ日本語出力用ツールをインストールする必要があります。"
      ],
      "metadata": {
        "id": "HwFCtuS0QH2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -y install fonts-ipafont-gothic\n",
        "!pip install japanize-matplotlib"
      ],
      "metadata": {
        "id": "7fXxaQNywKGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 形態素解析体験\n",
        "\n",
        "形態素解析で指定テキストをトークンに分割する："
      ],
      "metadata": {
        "id": "K4lHwMg1S91I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# 分析用文章を指定\n",
        "text = \"\"\"\n",
        "ただし、曖昧な意味を持つ単語などは、対象によって解釈が異なる場合もあります。\n",
        "例えば、「ヤバい」という言葉は元々悪い意味で使われていましたが、最近ではポジティブな意味で使われるケースも出てきました。\n",
        "文脈によって意味の変わる言葉を扱う際には、注意が必要です。\n",
        "\"\"\"\n",
        "\n",
        "for token in ____:\n",
        "    print(token)"
      ],
      "metadata": {
        "id": "oBB_AQ-kTGrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 実データ解析練習\n",
        "\n",
        "内閣府[「景気ウォッチャー調査」](https://www5.cao.go.jp/keizai3/watcher/watcher_menu.html)データを利用し、街角の景気実感（タクシー運転手や小売店主の声）をテキスト化したものをテキストマイニング手法で分析しましょう。"
      ],
      "metadata": {
        "id": "VBfmp-G6yc8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ステップ１：データをダウンロード\n",
        "\n",
        "[調査概要](https://www5.cao.go.jp/keizai3/watcher/watcher_mokuteki.html#mokuteki)を確認してから、「公表資料（統計表一覧）」から最新の月次統計表（csv形式）をダウンロードします。\n",
        "\n",
        "Excelなどでデータを確認し、「追加説明及び具体的状況の説明」列に注目させます。"
      ],
      "metadata": {
        "id": "DRd2dYDD0kcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ステップ２：データを読み込み\n",
        "\n",
        "ダウンロードしたcsvファイルをColabの「ファイル」にアップロードしてください。\n",
        "（*接続を解除したら自動で削除されるため、使うたびにアップロードが必要です。*）\n",
        "\n",
        "次に、データを読み込み、中身を確認しましょう。"
      ],
      "metadata": {
        "id": "cMeNSH3g12ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# データの読み込み（内閣府からダウンロードしたCSVファイル）\n",
        "df = pd.read_csv(_____)\n",
        "\n",
        "# データの中身を見てみる\n",
        "print(\"--- 元のデータ ---\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "6e9UwW6W0hFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ステップ３：テキスト抽出と形態素解析\n",
        "\n",
        "まずはテキストマイニング用に文章を抽出します。"
      ],
      "metadata": {
        "id": "COy8Re-l4Y0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 注目される列のデータだけを取り出してリストにします\n",
        "text_list = ______.tolist()\n",
        "\n",
        "# 欠損値（空欄）があるとうまくいかないので、文字列型に変換して結合\n",
        "text_data = ' '.join(map(str, text_list))\n",
        "\n",
        "# 最初の100文字だけを確認\n",
        "print(\"▼ 分析対象のテキストデータ:\")\n",
        "print(______)"
      ],
      "metadata": {
        "id": "2ICIcReN2_-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に、形態素解析（文章を単語にバラバラにする）を行い、名詞と形容詞だけを取り出します。"
      ],
      "metadata": {
        "id": "vyp1V0vEvf-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_list = []\n",
        "\n",
        "# 名詞と形容詞だけを取り出す\n",
        "for token in tokenizer.tokenize(text_data):\n",
        "    if token.part_of_speech.split(',')[0] in [______]:\n",
        "        # 「する」「いる」などの一般的すぎる言葉を除外（ストップワード）\n",
        "        if token.base_form not in [\"こと\", \"ため\", \"よう\", \"いる\", \"ある\", \"する\"]:\n",
        "            words_list.append(token.base_form)\n",
        "\n",
        "# 最初の10単語だけを確認\n",
        "print(\"抽出された単語:\", ______)"
      ],
      "metadata": {
        "id": "n0HhLAsrvgZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ステップ４：頻出語ランキングの集計とグラフ化"
      ],
      "metadata": {
        "id": "Xz3qp6bGu5_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# 単語の出現回数を数える\n",
        "\n",
        "\n",
        "# 上位10個を取り出す\n",
        "\n",
        "\n",
        "# 表（データフレーム）にして表示\n",
        "df_freq = pd.DataFrame(top_10, columns=['単語', '出現回数'])\n",
        "print(\"▼ 頻出語ランキングベスト10\")\n",
        "display(df_freq)"
      ],
      "metadata": {
        "id": "Hogc0Dmiu60L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に、棒グラフで可視化します。"
      ],
      "metadata": {
        "id": "1z_8Lr326rT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "\n",
        "# グラフ用にデータを分ける\n",
        "words = [x[0] for x in top_10]\n",
        "counts = [x[1] for x in top_10]\n",
        "\n",
        "# グラフの作成\n",
        "plt.figure(figsize=(10, 6))\n",
        "# 横棒グラフ (barh) を作成\n",
        "plt.barh(_______)\n",
        "plt.title(____)\n",
        "plt.xlabel(____)\n",
        "plt.ylabel(____)\n",
        "\n",
        "# 上位が上に来るように順番を反転\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6) # グリッド線\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0FjWZtnU6qMz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}