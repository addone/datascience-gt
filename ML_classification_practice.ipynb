{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pythonで機械学習による分類の簡単な例を実践しましょう。\n",
        "\n",
        "\n",
        "1.   データの２分類（KNN法）\n",
        "2.   手書き数字認識（SVMモデル）\n",
        "3.   カラー画像の認識（にゅうらー）\n",
        "\n"
      ],
      "metadata": {
        "id": "PHcQhvw7yLKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNNによる分類"
      ],
      "metadata": {
        "id": "zqHBWlCS8qaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず、2種類のクラスに分類する簡単な例を見てみましょう。この例では、`np.random.rand`を使用してランダムに生成した2次元のデータを[K最近傍法（KNN）](https://zero2one.jp/learningblog/k-nearest-neighbor-python/)で分類し、結果を可視化します。"
      ],
      "metadata": {
        "id": "t2m7xJgn8yyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# データの生成\n",
        "X, y = make_classification(n_samples=200, n_features=2, n_classes=2, n_clusters_per_class=1, n_redundant=0, random_state=42)\n"
      ],
      "metadata": {
        "id": "nnagjMjscTWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "下にコードセルを追加し、生成したデータポイントを散布図で可視化しましょう。"
      ],
      "metadata": {
        "id": "rO4tfizyy1v1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "データは、x座標とy座標の2つの特徴（例：「滞在時間」「消費金額」）から構成されています。また、各データには、0か1のクラスラベルが付けられています。\n",
        "\n",
        "K近傍法は、与えられたデータに最も近い*K*個のデータ（`n_neighbors`）のクラスラベルを参考にして、新しいデータのクラスを予測するアルゴリズムです。まずは*K=3*の設定で学習モデルを作ります。"
      ],
      "metadata": {
        "id": "JVepcSRQceq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# データをトレーニングセットとテストセットに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# K最近傍法モデルの作成（n_neighborsの数値は分類結果にどう影響するか？）\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# （モデルで学習し、予測を行い、予測精度を計算してみましょう）\n"
      ],
      "metadata": {
        "id": "zYVArlhIFbX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "訓練したモデル内部では実際どのように分類したのでしょうか？"
      ],
      "metadata": {
        "id": "dyYiZj7RJWav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 決定境界を可視化\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1], label='Class 0 (True)', marker='o')\n",
        "plt.scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1], label='Class 1 (True)', marker='x')\n",
        "\n",
        "h = .02\n",
        "x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
        "y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "Z = knn_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contour(xx, yy, Z, colors='k', levels=[0.5], linewidths=3)\n",
        "\n",
        "plt.title('Simple Classification with KNN')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "d34GHYtm53wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# SVMによる手書き数字の認識\n",
        "\n",
        "次に、[MNISTデータセット](https://atmarkit.itmedia.co.jp/ait/articles/2001/22/news012.html)を使用しています。MNISTデータセットは、手書き数字の画像データセットで、0から9までの10種類の数字があります。\n",
        "\n",
        "まずはこのデータセットのテストデータの最初のいくつかの画像を可視化します。"
      ],
      "metadata": {
        "id": "Lp8URoE5yfkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# MNISTデータセットを読み込みます\n",
        "digits = datasets.load_digits()\n",
        "data = digits.data\n",
        "target = digits.target\n",
        "\n",
        "# データをトレーニングセットとテストセットに分割します\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# テストデータの最初のいくつかの画像を示す\n",
        "plt.figure(figsize=(12, 4))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(X_test[i].reshape(8, 8), cmap='gray')\n",
        "    plt.title(f'{y_test[i]}')\n",
        "    plt.axis('off')\n"
      ],
      "metadata": {
        "id": "9tbc7pHxsWaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNISTデータセットは手書き数字のデータセットであり、通常は画像認識のタスクに使用されます。この例では、各手書き数字が8x8の行列としてフラット化されている特徴を使用しています。\n",
        "\n",
        "以下では、[Support Vector Machine (SVM)](https://avinton.com/academy/svm/)を使って画像を分類します。線形カーネルを使用しますが、他のカーネルも試すことができます。\n",
        "\n",
        "また、ハイパーパラメータの調整も重要です。`C`パラメータ（採用する決定境界にどれぐらいの誤分類を許すか；大きいほど厳しい）が結果に影響します。"
      ],
      "metadata": {
        "id": "O3bLqNLVIvdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVMモデルを定義します\n",
        "svm_model = SVC(kernel='linear', C=10, gamma='auto')\n",
        "\n",
        "# （モデルで学習し、予測を行い、予測精度を計算してみましょう）\n"
      ],
      "metadata": {
        "id": "zPUmQdkUJsoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "実際の予測結果を見ていきましょう。"
      ],
      "metadata": {
        "id": "nf9E51mBKKiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータの最初のいくつかの画像を表示し、SVMの予測結果を示す\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(20):\n",
        "    plt.subplot(4, 5, i + 1)\n",
        "    plt.imshow(X_test[i].reshape(8, 8), cmap='gray')\n",
        "    plt.title(f'{y_test[i]} (Predicted: {y_pred[i]})')\n",
        "    plt.axis('off')\n"
      ],
      "metadata": {
        "id": "Yl5u_IcX8O1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 画像認識（ニューラルネットワーク）\n",
        "\n",
        "より一般的な画像分類タスクでは、畳み込みニューラルネットワーク(CNN)などの深層学習モデルがSVMよりも良い性能を発揮することがあります。\n",
        "\n",
        "以下はニューラルネットワークを使用してCIFAR-10データセットを分類する例です。\n",
        "\n",
        "[CIFAR-10（Canadian Institute for Advanced Research - 10）データセット](https://atmarkit.itmedia.co.jp/ait/articles/2006/10/news021.html)は、Alex Krizhevsky氏／Vinod Nair氏／Geoffrey Hinton氏によって収集された、10の異なるクラスに属する32x32ピクセルのカラー画像で構成される公開データセットです。各画像はRGB形式で、10のクラスそれぞれに約6,000枚ずつの画像が含まれています。\n",
        "\n",
        "CIFAR-10データセットのクラスは以下の通りです：\n",
        "\n",
        "0. Airplane（飛行機）\n",
        "1. Automobile（自動車）\n",
        "1. Bird（鳥）\n",
        "1. Cat（猫）\n",
        "1. Deer（鹿）\n",
        "1. Dog（犬）\n",
        "1. Frog（カエル）\n",
        "1. Horse（馬）\n",
        "1. Ship（船）\n",
        "1. Truck（トラック）\n",
        "\n",
        "各クラスは、異なる視点や背景で撮影された画像で構成され、一般的な物体認識タスクのベンチマークとして使用されています。CIFAR-10データセットは、機械学習やディープラーニングアルゴリズムの評価やモデルの訓練に広く利用されています。\n"
      ],
      "metadata": {
        "id": "wbpV_mHoMfWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# CIFAR-10データセットの読み込み\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# データの前処理\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0  # ピクセル値を0から1の範囲に正規化\n",
        "train_labels = to_categorical(train_labels, 10)  # ラベルをone-hotエンコード\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "# ラベルネームを設定\n",
        "label_names = {}\n"
      ],
      "metadata": {
        "id": "l3wl_5I2IBkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータの最初のいくつかの画像を表示する\n",
        "plt.figure(figsize=(12, 4))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    # 画像を表示\n",
        "    plt.imshow(test_images[i])\n",
        "    # 実際のラベルを表示\n",
        "    true_label = np.argmax(test_labels[i])\n",
        "    plt.title(f'Category: {true_label}')\n",
        "    plt.axis('off')\n"
      ],
      "metadata": {
        "id": "GY2ZbZctBoyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下のセルで、[3層ニューラルネットワーク](https://hogetech.info/ml/dl/neural-network)を構築しましょう。"
      ],
      "metadata": {
        "id": "-usy_VQjSZR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ニューラルネットワークのモデルの構築\n",
        "\n",
        "# モデルのコンパイル\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# モデルの概要を表示\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "F0ptbXBAR45u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "作ったモデルでトレーニングし、トレーニングプロセス中におけるモデルの性能の進化を**学習曲線**で可視化しましょう。\n",
        "\n",
        "典型的な学習曲線には、トレーニングセットと検証セット（またはテストセット）に対する損失（エラー）と性能指標（例えば、精度）の推移が含まれます。"
      ],
      "metadata": {
        "id": "A97v8sT6E_pZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルのトレーニング\n",
        "\n",
        "# テストデータで評価\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc * 100:.2f}%')\n",
        "\n",
        "# 学習曲線の表示\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n"
      ],
      "metadata": {
        "id": "wet6VVwIGDhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "次に、モデルで予測しましょう。テストデータの最初の10枚の画像を表示し、各画像に対するモデルの予測（分類結果）と実際のラベルを表示しています。結果が正しかった場合は青で、誤っていた場合は赤で表示されます。"
      ],
      "metadata": {
        "id": "7bRTOm5qVmW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの予測\n",
        "\n",
        "# テストデータの最初のいくつかの画像を表示し、予測と実際のラベルを表示する\n",
        "plt.figure(figsize=(12, 10))\n",
        "for i in range(20):\n",
        "    plt.subplot(4, 5, i + 1)\n",
        "    # 画像を表示\n",
        "    plt.imshow(test_images[i])\n",
        "    # 予測と実際のラベルを表示\n",
        "    predicted_label = np.argmax(predictions[i])\n",
        "    true_label = np.argmax(test_labels[i])\n",
        "    # 予測が正しかったら青く、間違っていたら赤く表示\n",
        "    color = 'blue' if predicted_label == true_label else 'red'\n",
        "    plt.title(f'Predicted: {label_names[predicted_label]}\\nTrue: {label_names[true_label]}', color=color)\n",
        "    plt.axis('off')\n"
      ],
      "metadata": {
        "id": "ariIy59bVh5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "この例は、シンプルな全結合層のニューラルネットワークを構築し、CIFAR-10データセットでトレーニングしています。モデルの構造は簡潔で、実行スピードを優先しています。より高度な性能が必要な場合は、畳み込みニューラルネットワーク（CNN）などのより複雑なモデルを検討することができます。\n",
        "\n",
        "（ChatGPTおよびGoogle Bardの生成結果をもとに作成。「CNNでCIFAR-10を高い精度で分類するには？」とGeminiなどに問いかけてみてください。）\n",
        "\n",
        "---\n",
        "\n",
        "# その他応用例：\n",
        "\n",
        "[「機械学習（進化的ニューラルネットワーク）を利用してスーパーマーリオをプレイしてみた」（Youtube）](https://youtu.be/qv6UVOQ0F44?si=YRKS6VrnDgXJAdzt)\n"
      ],
      "metadata": {
        "id": "lGxwYUwcT4EN"
      }
    }
  ]
}